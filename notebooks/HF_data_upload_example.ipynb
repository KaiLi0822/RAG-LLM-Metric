{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T17:58:05.090903Z",
     "start_time": "2025-02-16T17:58:00.242347Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0103bc6ab449ef8ee5beef365fa444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6161a8911f146ca93f41266eaf84c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9806bc66afa844f2b8999f4274bb6441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fffd335415476886392cddcd9e5f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e17e61d72bf4c08960c9657f78ff284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb7edbed5074c7ebc845b73df90083d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25958903a79c42ba80412dc44537a49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.96k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset uploaded successfully to RAGEVALUATION-HJKMY/ragbench_10row_tester\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from huggingface_hub import login, HfApi\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "NEW_DATASET_NAME = \"RAGEVALUATION-HJKMY/ragbench_10row_tester\"  \n",
    "SPLITS_TO_SAMPLE = ['train', 'test', 'validation']\n",
    "\n",
    "original_dataset = load_dataset(\"rungalileo/ragbench\", \"delucionqa\")\n",
    "\n",
    "new_dataset_dict = {}\n",
    "for split in SPLITS_TO_SAMPLE:\n",
    "    if split in original_dataset:\n",
    "        sampled_split = original_dataset[split].select(range(10))\n",
    "        new_dataset_dict[split] = sampled_split  # Directly assign the Dataset\n",
    "\n",
    "new_dataset = DatasetDict(new_dataset_dict)\n",
    "\n",
    "\n",
    "login(token=os.getenv('HF_TOKEN'))\n",
    "\n",
    "new_dataset.push_to_hub(NEW_DATASET_NAME)\n",
    "\n",
    "logger.info(f\"Dataset uploaded successfully to {NEW_DATASET_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e812d6f5e14e343a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T17:56:46.404166Z",
     "start_time": "2025-02-16T17:56:46.401888Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa7311b03f4a867",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
