[tool.poetry]
name = "RAG-LLM-Metric"
version = "0.1.0"
description = "My project description"
authors = ["Your Name <you@example.com>"]
readme = "README.md"
packages = [{include = "evaluator"}, {include = "data_annotator"}, {include = "execution_pipeline"}, {include = "agent"}]

[tool.poetry.dependencies]
python = ">=3.10,<3.14"
openai = "^1.12.0"
requests = "^2.31.0"
datasets = "^2.16.1"
python-dotenv = "^1.0.0"
ipykernel = "^6.19.0"
huggingface-hub = "^0.28"
transformers = "^4.48"
sentence-transformers = "^3.3"
# CPU version will be installed by default from PyPI
torch = { version = ">=2.1.2", optional = true }
ragas = "^0.2.14"
duckduckgo-search = "^7.5.5"
autogen = "^0.8.6"
autogen-agentchat = "==0.4.7"
bert-score = "^0.3.13"
pandas = "^2.2.3"

[tool.poetry.group.dev.dependencies]
ipykernel = "^6.29.5"

# Add PyTorch CUDA repository as a source
[[tool.poetry.source]]
name = "pytorch"
url = "https://download.pytorch.org/whl/cu121"
priority = "explicit"

# Define optional GPU dependency (same package name but different source)
[tool.poetry.extras]
cpu = ["torch"]
gpu = ["torch"]

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[virtualenvs]
create = true
in-project = true